{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFgf6yzqHBL1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3KVCGRmVK-K"
   },
   "outputs": [],
   "source": [
    "def reshaping(x):\n",
    "    \"\"\"\n",
    "    Reshape the data created with numpy. \n",
    "    \"\"\"\n",
    "    return x.reshape(x.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-vamXuEVNKF"
   },
   "outputs": [],
   "source": [
    "#Packages\n",
    "import os\n",
    "import scipy \n",
    "from scipy.constants import pi\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXEeXw8oVQcX"
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 20\n",
    "MEDIUM_SIZE = 22\n",
    "BIGGER_SIZE = 24\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUTsgsrzVSL9"
   },
   "outputs": [],
   "source": [
    "N0 = 1000\n",
    "Nb = 1000 # Number of points in the boundaries and initial value.  \n",
    "Nf = 20000 # Number of collocated points.\n",
    "\n",
    "SMALL = 1e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cifrkfJcZgpD"
   },
   "outputs": [],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9pkKpqdZpik"
   },
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "a = symbols('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fZFWcdkZpku"
   },
   "outputs": [],
   "source": [
    "from sympy import roots, solve_poly_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nHO2FpRZpnJ"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6x2tufdMZppN",
    "outputId": "06d1d2b1-850f-4b25-c30d-6995e8549e55"
   },
   "outputs": [],
   "source": [
    "solve(a**3 - pi*a**2 + 2*a -  pi, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PY2GkFHzZprw"
   },
   "outputs": [],
   "source": [
    "a2  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6j9R2PDJZptT"
   },
   "outputs": [],
   "source": [
    "a1 = 2.82721849525758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phivpmN0ZpxV"
   },
   "outputs": [],
   "source": [
    "omega = ((a1**2 + a2**2)*(1-a1*2 + a2*2))/(a2**2 - a1**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMP6Y9LVZ1z8",
    "outputId": "689b3b14-08a5-4dfe-e31f-8202783c131c"
   },
   "outputs": [],
   "source": [
    "omega "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRWT77SUZ11i"
   },
   "outputs": [],
   "source": [
    "space_IV = np.random.uniform(0 + SMALL, 1 - SMALL, N0)\n",
    "space_IV = reshaping(space_IV)\n",
    "x_IV = space_IV\n",
    "t_IV = 0*space_IV\n",
    "u_IV_1 = a1*tf.cos(2*pi*x_IV)\n",
    "v_IV_1 = a1*tf.sin(2*pi*x_IV)\n",
    "u_IV_2 = a2*tf.cos(2*pi*x_IV)\n",
    "v_IV_2 = a2*tf.sin(2*pi*x_IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "LyA_LK1DZ14I",
    "outputId": "a1e1975b-05fb-4a6a-f5c9-d7a6959a6019"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_IV, t_IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "d0gZSZ4rVkO8",
    "outputId": "0032350e-ca5b-4676-916b-05d93a6cf9a1"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_IV, t_IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVj-_33kVnCy"
   },
   "outputs": [],
   "source": [
    "# Boundary Condition\n",
    "time_BC = np.random.uniform(0 + SMALL, pi/2  - SMALL ,Nb)\n",
    "time_BC = reshaping(time_BC)\n",
    "# Boundary Condition x = 0\n",
    "t_lb = time_BC\n",
    "x_lb = 0*time_BC  \n",
    "u_lb_1 = 0*x_lb\n",
    "# Boundary Condition x = 1\n",
    "t_ub = time_BC\n",
    "x_ub = 0*time_BC + 1\n",
    "u_ub_1 = 0*x_ub\n",
    "# Boundary Condition\n",
    "u_BC_1 = np.concatenate((u_lb_1, u_ub_1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZ19Cz36VqzJ"
   },
   "outputs": [],
   "source": [
    "# Boundary Condition x = 0\n",
    "v_lb_1 = 0*x_lb\n",
    "# Boundary Condition x = 1\n",
    "v_ub_1 = 0*x_ub\n",
    "# Boundary Condition\n",
    "v_BC_1 = np.concatenate((v_lb_1, v_ub_1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrtPdlnbVspw"
   },
   "outputs": [],
   "source": [
    "# Boundary Condition x = 0\n",
    "u_lb_2 = 0*x_lb\n",
    "# Boundary Condition x = 1\n",
    "u_ub_2 = 0*x_ub\n",
    "# Boundary Condition\n",
    "u_BC_2 = np.concatenate((u_lb_2, u_ub_2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oRF5ZpYVvX5"
   },
   "outputs": [],
   "source": [
    "# Boundary Condition x = 0\n",
    "v_lb_2 = 0*x_lb\n",
    "# Boundary Condition x = 1\n",
    "v_ub_2 = 0*x_ub\n",
    "# Boundary Condition\n",
    "v_BC_2 = np.concatenate((v_lb_2, v_ub_2), axis=0)\n",
    "t_BC = np.concatenate((t_lb, t_ub), axis=0)\n",
    "x_BC = np.concatenate((x_lb, x_ub), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "6NW_68i9Vw3J",
    "outputId": "10232cc4-10fa-4747-a993-bac4659afd89"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_BC, t_BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbnRKE7jVzUV"
   },
   "outputs": [],
   "source": [
    "x_collocated = np.random.uniform(0 + SMALL, 1 - SMALL, Nf)\n",
    "x_collocated = reshaping(x_collocated)\n",
    "t_collocated = np.random.uniform(0 + SMALL, pi/2 - SMALL, Nf)\n",
    "t_collocated = reshaping(t_collocated)\n",
    "xx, tt = np.concatenate((x_collocated, x_IV, x_BC), axis=0), np.concatenate((t_collocated, t_IV, t_BC), axis=0)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((xx, tt))\n",
    "batch_size = xx.shape[0]\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "Hr5UHSRGV2O8",
    "outputId": "e78db8ed-68f9-4c8b-d024-3f54e98d2418"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xx,tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-3eQ3CrV3vz"
   },
   "outputs": [],
   "source": [
    "n_targets = 4\n",
    "n_hidden_layers, n_hidden_neurons = 9,20\n",
    "input_x = tf.keras.Input(shape=(1,))\n",
    "input_t = tf.keras.Input(shape=(1,))\n",
    "inputs = tf.keras.layers.concatenate([input_x, input_t])\n",
    "initializer = tf.keras.initializers.GlorotNormal()\n",
    "x = tf.keras.layers.Dense(n_hidden_neurons, activation='tanh', kernel_initializer=initializer, dtype=tf.float64)(inputs)\n",
    "for hidden in range(n_hidden_layers-1):\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "    x = tf.keras.layers.Dense(n_hidden_neurons, activation='tanh', kernel_initializer=initializer, dtype=tf.float64)(x)\n",
    "initializer = tf.keras.initializers.GlorotNormal()\n",
    "outputs = tf.keras.layers.Dense(n_targets, activation='tanh', kernel_initializer=initializer, dtype=tf.float64)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_x, input_t], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEFEJBgbV689"
   },
   "outputs": [],
   "source": [
    "# Instantiate an optimizer to train the model.\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-02,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.96)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lRs6qR5V8jn"
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6E-YRL49V-Gw"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        # Boundary conditions evaluation\n",
    "        BC_pred = model([x_BC, t_BC], training = True)\n",
    "        u_BC_1_pred = BC_pred[:, 0:1]\n",
    "        v_BC_1_pred = BC_pred[:, 1:2]\n",
    "        u_BC_2_pred = BC_pred[:, 2:3]\n",
    "        v_BC_2_pred = BC_pred[:, 3:4]\n",
    "\n",
    "        loss_u_BC_1 = loss_fn(u_BC_1, u_BC_1_pred)\n",
    "        loss_v_BC_1 = loss_fn(v_BC_1, v_BC_1_pred)\n",
    "        loss_u_BC_2 = loss_fn(u_BC_2, u_BC_2_pred)\n",
    "        loss_v_BC_2 = loss_fn(v_BC_2, v_BC_2_pred)\n",
    " \n",
    "        # Initial values evaluation\n",
    "        IV_pred = model([x_IV, t_IV], training=True) \n",
    "        u_IV_1_pred = IV_pred[:, 0:1] \n",
    "        v_IV_1_pred = IV_pred[:, 1:2] \n",
    "        u_IV_2_pred = IV_pred[:, 2:3] \n",
    "        v_IV_2_pred = IV_pred[:, 3:4] \n",
    "        \n",
    "        loss_u_IV_1 = 1000*loss_fn(u_IV_1, u_IV_1_pred)\n",
    "        loss_v_IV_1 = 1000*loss_fn(v_IV_1, v_IV_1_pred)\n",
    "        loss_u_IV_2 = 1000*loss_fn(u_IV_2, u_IV_2_pred)\n",
    "        loss_v_IV_2 = 1000*loss_fn(v_IV_2, v_IV_2_pred)\n",
    "        \n",
    "        # Collocated points evaluation - Differential Equation \n",
    "        with tf.GradientTape(persistent=True) as tape_diff:\n",
    "            tape_diff.watch(x)\n",
    "            tape_diff.watch(t)\n",
    "            pred = model([x, t], training=True)\n",
    "            u_1_pred = pred[:, 0:1]\n",
    "            v_1_pred = pred[:, 1:2]\n",
    "            u_2_pred = pred[:, 2:3]\n",
    "            v_2_pred = pred[:, 3:4]\n",
    "            \n",
    "            \n",
    "            u_1_x  = tape_diff.gradient(u_1_pred, x)\n",
    "            u_2_x  = tape_diff.gradient(u_2_pred, x)\n",
    "            v_1_x = tape_diff.gradient(v_1_pred, x)\n",
    "            v_2_x = tape_diff.gradient(v_2_pred, x)\n",
    "            u_1_t = tape_diff.gradient(u_1_pred, t)\n",
    "            v_1_t = tape_diff.gradient(v_1_pred, t)\n",
    "            u_2_t = tape_diff.gradient(u_2_pred, t)\n",
    "            v_2_t = tape_diff.gradient(v_2_pred, t)\n",
    "\n",
    "        del tape_diff\n",
    "        \n",
    "\n",
    "        f_u_1 = -v_1_t - v_2_x + u_1_pred - (u_1_pred)**3 - (u_1_pred)*(v_1_pred)**2 + (u_1_pred)*(u_2_pred)**2 + (u_1_pred)*(v_1_pred)**2\n",
    "        f_v_1 = u_2_t + u_2_x - v_1_pred - (v_1_pred)*(u_1_pred)**2 - (v_1_pred)**3 + (v_1_pred)*(u_2_pred)**2 - (v_1_pred)*(v_2_pred)**2 \n",
    "        f_u_2 = - v_2_t - v_1_x - u_2_pred + (u_2_pred)*(u_1_pred)**2 + (u_2_pred)*(v_1_pred)**2 - (u_2_pred)**3 - (u_2_pred)*(v_2_pred)**2\n",
    "        f_v_2 = u_2_t + u_1_x - v_2_pred + (v_2_pred)*(u_1_pred)**2 + (v_2_pred)*(v_1_pred)**2 - (v_2_pred)**3 - (v_2_pred)*(u_2_pred)**2\n",
    "    \n",
    "        \n",
    "        loss_f_u_1 = loss_fn(0, f_u_1)\n",
    "        loss_f_v_1 = loss_fn(0, f_v_1)\n",
    "        loss_f_u_2 = loss_fn(0, f_u_2)\n",
    "        loss_f_v_2 = loss_fn(0, f_v_2)\n",
    "        \n",
    "        h_1_pred = u_1_pred**2 + v_1_pred**2\n",
    "        h_2_pred = u_2_pred**2 + v_2_pred**2\n",
    "        \n",
    "        # General loss function\n",
    "        loss = loss_f_u_1 + loss_f_v_1 + loss_f_u_2 + loss_f_v_2 + loss_u_BC_1 + loss_u_BC_2 + loss_v_BC_1 + loss_v_BC_2 + loss_u_IV_1 + loss_v_IV_1 + loss_u_IV_2 + loss_v_IV_2\n",
    "        \n",
    "    # Regular backpropagation\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    \n",
    "    \n",
    "    return loss,loss_f_u_1 ,loss_f_v_1, loss_f_u_2, loss_f_v_2, loss_u_BC_1, loss_u_BC_2, loss_v_BC_1, loss_v_BC_2, loss_u_IV_1, loss_v_IV_1, loss_u_IV_2, loss_v_IV_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xt4fIgAlXapX"
   },
   "outputs": [],
   "source": [
    "def Callback_EarlyStopping(LossList, min_delta=0.1, patience=20):\n",
    "    #No early stopping for 2*patience epochs \n",
    "    if len(LossList)//patience < 2 :\n",
    "        return False\n",
    "    #Mean loss for last patience epochs and second-last patience epochs\n",
    "    mean_previous = np.mean(LossList[::-1][patience:2*patience]) #second-last\n",
    "    mean_recent = np.mean(LossList[::-1][:patience]) #last\n",
    "    #you can use relative or absolute change\n",
    "    delta_abs = np.abs(mean_recent - mean_previous) #abs change\n",
    "    delta_abs = np.abs(delta_abs / mean_previous)  # relative change\n",
    "    if delta_abs < min_delta :\n",
    "        print(\"*CB_ES* Loss didn't change much from last %d epochs\"%(patience))\n",
    "        print(\"*CB_ES* Percent change in loss value:\", delta_abs*1e2)\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YzZe2BHeXdH8",
    "outputId": "cd70189b-a079-4184-aace-020e0aecef1e"
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "start_time_outer = time.time()\n",
    "loss_seq = []\n",
    "loss_seq = []\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time_inner = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, t_batch_train) in enumerate(train_dataset):\n",
    "        loss_train, loss_f_u_1, loss_f_v_1, loss_f_u_2, loss_f_v_2, loss_u_BC_1, loss_u_BC_2, loss_v_BC_1, loss_v_BC_2, loss_u_IV_1, loss_v_IV_1, loss_u_IV_2, loss_v_IV_2 = train_step(x_batch_train, t_batch_train)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(f\"Training loss (for one batch) at step {step}: {format(float(loss_train), 'e')}\")\n",
    "            print(f\"f_u_1 loss (for one batch) at step {step}: {format(float(loss_f_u_1), 'e')}\")\n",
    "            print(f\"f_u_2 loss (for one batch) at step {step}: {format(float(loss_f_u_2), 'e')}\")\n",
    "            print(f\"f_v_1 loss (for one batch) at step {step}: {format(float(loss_f_v_1), 'e')}\")\n",
    "            print(f\"f_v_2 loss (for one batch) at step {step}: {format(float(loss_f_v_2), 'e')}\")\n",
    "            print(f\"u_BC_1 loss (for one batch) at step {step}: {format(float(loss_u_BC_1), 'e')}\")\n",
    "            print(f\"u_BC_2 loss (for one batch) at step {step}: {format(float(loss_u_BC_2), 'e')}\")\n",
    "            print(f\"v_BC_1 loss (for one batch) at step {step}: {format(float(loss_v_BC_1), 'e')}\")\n",
    "            print(f\"v_BC_2 loss (for one batch) at step {step}: {format(float(loss_v_BC_2), 'e')}\")\n",
    "            print(f\"u_IV_1 loss (for one batch) at step {step}: {format(float(loss_u_IV_1), 'e')}\")\n",
    "            print(f\"u_IV_2 loss (for one batch) at step {step}: {format(float(loss_u_IV_2), 'e')}\")\n",
    "            print(f\"v_IV_1 loss (for one batch) at step {step}: {format(float(loss_v_IV_1), 'e')}\")\n",
    "            print(f\"v_IV_2 loss (for one batch) at step {step}: {format(float(loss_v_IV_2), 'e')}\")\n",
    "            print(f\"Seen so far: {(step + 1) * batch_size} samples\")\n",
    "    \n",
    "    # Stop criteria\n",
    "    loss_seq.append(loss_train)  \n",
    "    stopEarly = Callback_EarlyStopping(loss_seq, min_delta=1e-02, patience=1000)\n",
    "    if stopEarly or loss_train < 1e-04:\n",
    "        print(\"Callback_EarlyStopping signal received at epoch= %d/%d\"%(epoch,epochs))\n",
    "        print(\"Terminating training \")\n",
    "        break\n",
    "        \n",
    "    \n",
    "    print(f\"Time taken: {round(time.time() - start_time_inner, 2)}s\")\n",
    "print(100*'=')\n",
    "print(f\"Total time taken: {round(time.time() - start_time_outer, 2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqKEggqraCML"
   },
   "outputs": [],
   "source": [
    "N_test = 50\n",
    "time_test = 0.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvAf1KphXhdO"
   },
   "outputs": [],
   "source": [
    "x_values = np.linspace(0, 1, N_test)\n",
    "h_hat = model.predict([x_values, time_test*np.ones(N_test)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JxSai7SbUAX"
   },
   "outputs": [],
   "source": [
    "\n",
    "u_1_hat = h_hat[:, 0:1]\n",
    "v_1_hat = h_hat[:, 1:2]\n",
    "u_2_hat = h_hat[:, 2:3]\n",
    "v_2_hat = h_hat[:, 3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCGHstKFkRdt"
   },
   "outputs": [],
   "source": [
    "k = 2*pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bZIZbAIaA8-"
   },
   "outputs": [],
   "source": [
    "def anal_1(x,t):\n",
    "    resp = a1*np.cos(k*x - omega*t)\n",
    "    return np.array(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTm9ZLt2avmp"
   },
   "outputs": [],
   "source": [
    "def anal_2(x,t):\n",
    "    resp = a1*np.sin(k*x - omega*t)\n",
    "    return np.array(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkqMRnKhbCjG"
   },
   "outputs": [],
   "source": [
    "def anal_3(x,t):\n",
    "    resp = a2*np.cos(k*x - omega*t)\n",
    "    return np.array(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBDvO2GGbFt_"
   },
   "outputs": [],
   "source": [
    "def anal_4(x,t):\n",
    "    resp = a2*np.sin(k*x - omega*t)\n",
    "    return np.array(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "wqGPlD2KaWxU",
    "outputId": "75136f9c-b24d-40c5-8906-b974134adcae"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "im = plt.figure(figsize=(15,7))\n",
    "plt.plot(x_values, anal_4(x_values, time_test), '-', label='Analytical solution')\n",
    "plt.plot(x_values, v_2_hat, '-o', label='Neural network prediction')\n",
    "plt.xlabel('$\\\\xi$')\n",
    "plt.ylabel('v_2($\\\\xi,\\\\tau$)')\n",
    "plt.ylim(-4, 4)\n",
    "plt.title('Example - 3, $\\\\omega_{1} = \\ldots = \\omega_{4} = 1000$,$\\\\omega_{5} = \\ldots = \\omega_{12} = 1$  ')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLDE.ipynb\"\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
